---
title: "Final Project"
author: "Warner Rose"
output: 
  html_document:
    toc: True
---
# Introduction

This paper explores the process for developing models to forecast economic time series. The focus is on building many models to be tested on out-of-sample data and refined on a regular basis. 

While there is an extensive literature on time series models, this paper will narrow its focus to some **exponential smoothing** methods and their performance forecasting the US unemployment rate.

Models will be compared for 2 types of forecasting scenarios: **1)** medium term (up to 6 months ahead) and **2)** short term (1 month ahead). The latter is how the **fredcast** forecasting competition works.

# Data 

The Federal Reserve maintains a site that hosts economic data called [FRED (Federal Reserve Economic Data)](https://fred.stlouisfed.org/). They also have a monthly forecasting contest called [**fredcast**](https://research.stlouisfed.org/useraccount/fredcast/). The purpose of fredcast is to forecast the following 4 time series:

* [**Unemployment Rate**](https://fred.stlouisfed.org/series/UNRATE)
* [**Real GDP**](https://fred.stlouisfed.org/series/GDPC1)
* [**Payroll Employment**](https://fred.stlouisfed.org/series/PAYEMS)
* [**Consumer Price Index**](https://fred.stlouisfed.org/series/CPIAUCSL)

While the techniques to be discussed can be applied to all 4 series, this paper will focus only on the **unemployment rate** for brevity.

# Packages

```{r message=FALSE, warning=FALSE, include=FALSE}
library(forecast)
library(fredr)
library(zoo)
library(tidyverse)
library(reshape2)
library(dygraphs)
library(lubridate)
```


The package **forecast** is an extensive library developed by [Rob Hyndman](https://robjhyndman.com/) supporting a variety of time series models. **fredr** is a package for accessing the FRED api. It can be used to download data from FRED. **zoo** provides some helpful functions for date-formatted data. **dygraphs** is a great javascript-based library for visualizing time series data.

```{r warning=FALSE, include=FALSE}
gen_forecast_array <- function(model_list){
  
  forecast_list <- 
    purrr::map(model_list, function(x) forecast(x))
  
  actuals <- forecast_list[[1]]$x
  point_forecasts <- 
    purrr::map(forecast_list, function(x) x$mean)
  
  new_colnames <- c(names(model_list), 'actuals')
  point_forecasts[[length(point_forecasts)+1]] <- actuals
  names(point_forecasts)  <- new_colnames
  
  forecast_array <- Reduce(cbind, point_forecasts)
  dimnames(forecast_array) <- list(NULL, new_colnames)
  
  forecast_wide <- data.frame(forecast_array)
  
  forecast_date <- min(as.yearmon(time(forecast_list[[1]]$x)))
  forecast_date <- forecast_date + (1/12) * (1:nrow(forecast_wide))
  
  forecast_wide$date <- forecast_date
  
  #put holdout actuals back
  forecast_wide$actuals[is.na(forecast_wide$actuals)][1:6] <- tail(unr,6)
  
  forecast_long <- forecast_wide %>% 
                  reshape2::melt(id.vars=c('date'))
  names(forecast_long) <- c('date','model','value')
  
  list(forecast_wide, forecast_long, forecast_array)
}
```

```{r include=FALSE}
api_key <- "0e510a57a0086df706ac9c8fb852b706"
```

# Unemployment rate time series from FRED

Using my FRED api key and **fredr_key** function from the *fredr* package I authenticate my credentials:

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
fredr_key(api_key)
```

Download the monthly unemployment time series from FRED using **`fredr_series`**. 

```{r echo=TRUE}
unr <- fredr_series(series_id='UNRATE')
head(unr)
tail(unr)
```


```{r include=FALSE}
unr2 <- data.frame(unemp=as.matrix(unr),
                  date=as.yearmon(time(unr)))

unr2$diff_unemp <- c(NA, diff(unr2$unemp, 1))
```

```{r include=FALSE}
pay <- fredr_series(series_id="PAYEMS")
gdp <- fredr_series(series_id='A191RL1Q225SBEA')
cpi <- fredr_series(series_id="CPIAUCSL")

gdp2 <- data.frame(gdp=as.matrix(gdp),
                  date=as.yearmon(time(gdp)))

pay2 <- data.frame(payemp=as.matrix(pay),
                  date=as.yearmon(time(pay)))

cpi2 <- data.frame(cpi=as.matrix(cpi),
                  date=as.yearmon(time(cpi)))

master <- left_join(unr2, gdp2)
master <- left_join(master, pay2)
master <- left_join(master, cpi2)
```

The plot of the unemploymet rate shows varying **seasonality**.

```{r message=FALSE, warning=FALSE, include=FALSE}
min_date <- min(master$date)
max_date <- max(master$date)
master %>% 
  ggplot(aes(x=date, y=unemp)) + geom_line() + 
  ggtitle(paste0('US monthly unemployment rate, ',
                 min_date, ' - ', max_date)) + ylab('Unemployment %') 
```

```{r echo=FALSE}
title <- paste0('US monthly unemployment rate, ',
                 min_date, ' - ', max_date)
dygraph(unr, main=title) %>% dyRangeSelector() %>% 
  dyHighlight(highlightCircleSize = 4)
              
  
```

We can decompose the time series into **trend**, **seasonal**, and **random/error** components.

```{r echo=FALSE}
plot(decompose(unr))
```

Decomposing a series into appropriate terms is an essential part of exponential smoothing. We will see how the choice of either additive or multiplicative terms in the model impacts forecasting accuracy.

## Modeling 

### Exponential smoothing basics

Modeling a time series using exponential smoothing techniques consists of decomposing a time series into additive or multiplicative terms in order to account for seasonality and trend. Below are 2 simple examples of **strictly** additive and multiplicative models on a series **$x_t$**.

> $x_t = E_t + T_t + S_t$ (Additive)

> $x_t = E_t * T_t * S_t$ (Multiplicative)

Where $E_t$ is the random error term, $T_t$ is the trend term, and $S_t$ is the seasonal term.

There are **15** possible models based on components:

```{r include=FALSE}
smoothing_df <- data_frame(
  'Trend Component' = c('N (None)','A (Additive)', 'Ad (Additive damped)', 'M (Multiplicative)', 'Md (Multiplicative damped)'),
  'N (None)' = c('N,N','A,N','Ad,N','M,N','Md,N'), 'A (Additive)' = c('N,A','A,A','Ad,A','M,A','Md,A'),
  'M (Multiplicative)' = c('N,M','A,M','Ad,M','M,M','Md,M'))
```

### Fitting models

**6 month hold out sample**

A holdout sample consisting of the last 6 data points in the series will be used to measure the forecasting accuracy of the models. The models will be fit using the series **`unr2`**:
```{r}
unr2 <- head(unr, -6)
tail(unr)
tail(unr2)
```

**Fit multiple models** 

The *forecast* package function **`ets`** can fit any of the models in the above table. The **E** stands for "error", the **T** for "trend", and the **S** for "seasonality". As we will see below, these terms need to be specified when fitting a model.

A good strategy in R for fitting multiple models is to apply functions to lists:

```{r}
# forecast::ets(series, model='ETS')
# A = additive, M = multiplicative, N = none, Z = automatic
model_type <- c('ANN','AAA','MMM') 
ets_models <- purrr::map(model_type, function(x) forecast::ets(unr2, x))
names(ets_models) <- model_type
summary(ets_models)
```

The first model type **ANN** is the simplest exponential smoothing-based model with no trend or seasonal term. **AAA** contains additive error, trend, and seasonal terms. **MMM**  contains multiplicative error, trend, and seasonal terms.

**Getting forecasts in from multiple models**

All model forecasts and actuals are combined into formats **ggplot2** (long form data frame) and **dygraphs** (matrix array consisting of multiple time series) can work with. The heavy lifting is is done by the function **`gen_forecast_array`**. See source code for details.

```{r}
ets_forecasts1 <- gen_forecast_array(ets_models)
```

## Forecast comparison {.tabset .tabset-fade .tabset-pills}

### 6 month forecast

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(scales)

shapes <- c(20,2,7,10)
y_breaks <-  4 + 1:5 / 5 

p1 <- ets_forecasts1[[2]] %>%
  filter(date > '2016-01-01' &
           date < '2018-04-01') %>% 
  mutate(model = factor(model, levels=c('actuals',model_type)),
         actual = ifelse(model=='actuals', 'Actual','Forecast')) %>% 
  ggplot(aes(x=as.Date(date), y=value, colour=actual, group=model)) +
  geom_line() + geom_point(aes(shape=model), size = 2.5) +
  ggtitle("unemployment rate forecasts - 6 months out") +
  theme(
    legend.position = 'bottom',
    legend.title=element_blank()
  ) + 
  labs(x='Month', y='Unemployment rate %') + 
  scale_x_date(labels = date_format('%b-%Y')) +
  scale_y_continuous(breaks=y_breaks) +
  scale_shape_manual(values=shapes)

p1
```

The following plots show short to medium term forecasts from models fit with **`r max(as.yearmon(time(unr2)))`** as the latest month of data. The holdout sample is included in the plot.


### 1 month forecast

```{r include=FALSE}
model_type
holdout_size <- 6

truncated_series <- purrr::map(1:holdout_size, function(x) head(unr, -x))

ets_models2 <- vector('list', length=length(truncated_series)*3)
model_names <- character()

for(x in 1:length(model_type)){
  for(y in 1:length(truncated_series)){
      model <- ets(truncated_series[[y]], model_type[x])
      
      index <- (length(truncated_series) * (x-1) )+ y
      ets_models2[[index]] <- model
    
      model_date <- as.yearmon(time(tail(head(unr, -y), 1)))
      model_names <- c(model_names,
                       paste0(model_type[x],'-', model_date))
  }
}
names(ets_models2) <- model_names

```



```{r message=FALSE, warning=FALSE, include=FALSE}
gen_forecast_array2 <- function(model_list){
  
  forecast_list <- 
    purrr::map(model_list, function(x) forecast(x))
  
  actuals <- forecast_list[[1]]$x
  point_forecasts <- 
    purrr::map(forecast_list, function(x) x$mean)
  
  new_colnames <- c(names(model_list), 'actuals')
  point_forecasts[[length(point_forecasts)+1]] <- unr
  names(point_forecasts)  <- new_colnames
  
  forecast_array <- Reduce(cbind, point_forecasts)
  dimnames(forecast_array) <- list(NULL, new_colnames)
  
  forecast_wide <- data.frame(forecast_array)
  
  forecast_date <- as.yearmon(time(unr))
  forecast_date <- c(forecast_date, 
                     max(forecast_date ) + 
                       (1/12) * (1:(nrow(forecast_wide)-length(unr))))
  
  forecast_wide$date <- forecast_date
  
  #put holdout actuals back
  #forecast_wide$actuals[is.na(forecast_wide$actuals)][1:6] <- tail(unr,6)
  
  forecast_long <- forecast_wide %>% 
                  reshape2::melt(id.vars=c('date'))
  names(forecast_long) <- c('date','model','value')
  
  list(forecast_wide, forecast_long, forecast_array)
}

```

```{r include=FALSE}
ets_forecasts2 <- gen_forecast_array2(ets_models2)

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
graph_df1 <- ets_forecasts2[[2]] %>%
  filter(date > '2016-01-01' &
           date < '2018-01-01') %>% 
  mutate(model2 = gsub('\\..*', '', model),
         actual = ifelse(model=='actuals', 'Actual','Forecast'))

graph_df1 <- graph_df1 %>% filter((model2 %in% model_type &
                                    !is.na(value) |
                                  model2 == 'actuals'))

graph_df1$model_date <- gsub("^.*?\\.","", graph_df1$model)
graph_df1$model_date <- as.yearmon(gsub('[.]', ' ', graph_df1$model_date))

graph_df1 %>% 
  filter((model2 %in% model_type &
            month(graph_df1$date) - month(graph_df1$model_date) == 1) |
           model2=='actuals') %>% 
  ggplot(aes(x=as.Date(date), y=value, colour=actual, group=model2)) +
  geom_line() + geom_point(aes(shape=model2), size = 2.5) +
  ggtitle("unemployment rate forecasts - 1 month out") +
  theme(
    legend.position = 'bottom',
    legend.title=element_blank()
  ) + 
  labs(x='Month', y='Unemployment rate %') + 
  scale_x_date(labels = date_format('%b-%Y')) +
  scale_y_continuous(breaks=y_breaks) 

```

The above scenario of fitting models each forecasting 6 months out is not the same scenario as in fredcast. Fredcast is always based on forecasting 1 month into the future.

We will now fit the same models but this time simulate 6 separate fittings of models June-November. These models each forecast 1 month ahead.

Details of the algorithm for fitting multiple models on a rolling hold-out sample are in the source code.

## Forecasting error {.tabset .tabset-fade .tabset-pills}

### 6 month forecast error

```{r include=FALSE}
filter_dates <- max(ets_forecasts1[[1]]$date[!is.na(ets_forecasts1[[1]]$actuals)])
filter_dates <- rev(filter_dates - 1/12 * 0:5)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
forecast_error <- ets_forecasts1[[1]] %>% filter(date %in% filter_dates)
forecast_error$actuals <- tail(unr,6)
forecast_error2 <- reshape2::melt(forecast_error, id.vars=c('date','actuals')) 

forecast_error2$error <- as.numeric(forecast_error2$actuals) -
                          as.numeric(forecast_error2$value)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
forecast_error2 %>% 
  ggplot(aes(x=factor(months(date,abbreviate=T),
                         levels=c('Jul','Aug','Sep','Oct','Nov','Dec')), y=abs(error), fill=variable)) + 
  geom_bar(stat='identity', position='dodge') +
  labs(x='Month', y='Absolute error', title='forecasting error by model type - 6 months out') +
  scale_fill_discrete(labels=c('Constant','Additive', 'Multiplicative'), name='Model') +
  theme(
    legend.position = 'top',
    legend.title=element_blank(),
    axis.text.x = element_text(angle=45, hjust=1) 
  ) + facet_grid(.~as.factor(variable))
  
```

 The model consisting of multiplicative terms **MMM** had the lowest error for medium term (3-6 month) forecasts. The constant model **ANN** was the worst performing model.

In general, time series model error increases rapidly the further we forecast into the future. 

### 1 month forecasting error

```{r include=FALSE}
filter_dates <- as.yearmon('June 2017')
filter_dates <- rev(filter_dates + 1/12 * 0:5)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
forecast_error3 <- graph_df1 %>% filter(date %in% filter_dates)

forecast_error3 <- forecast_error3 %>% 
                    mutate(month_num = month(date) - month(model_date)) %>% 
                    filter(month_num %in% c(NA,1))

forecast2 <- forecast_error3 %>% spread(model2, value)  %>% select(-model, -model_date,
                                                                   -month_num)
actual_df <- forecast2 %>% filter(!is.na(actuals)) %>% 
              select(date, actuals)
forecast2 <- forecast2 %>% select(-actual, -actuals)
#forecast_error$actuals <- tail(unr,6)

f1 <- forecast2 %>% filter(!is.na(AAA)) %>% select(date, AAA)
f2 <- forecast2 %>% filter(!is.na(ANN)) %>% select(date, ANN)
f3 <- forecast2 %>% filter(!is.na(MMM)) %>% select(date, MMM)

final <- left_join(actual_df, f1)
final <- left_join(final, f2)
final <- left_join(final, f3)

final <- final %>% melt(id.vars =c('date','actuals')) %>% 
          mutate(error = actuals - value)
final$variable <- factor(final$variable, levels = model_type)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
final %>% 
  ggplot(aes(x=factor(months(date,abbreviate=T),
                         levels=c('Jun','Jul', 'Aug','Sep','Oct','Nov')), y=abs(error), fill=variable)) + 
  geom_bar(stat='identity', position='dodge') +
  labs(x='Month', y='Absolute error', title='forecasting error by model type - 1 month out') +
  scale_fill_discrete(labels=c('Constant','Additive', 'Multiplicative'), name='Model') +
  theme(
    legend.position = 'top',
    legend.title=element_blank(),
    axis.text.x = element_text(angle=45, hjust=1) 
  ) + facet_grid(.~as.factor(variable))
  
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

mon1 <- final %>% select(variable, 'error_1month'=error) %>%
        mutate(error_1month = abs(error_1month)) %>% 
        group_by(variable) %>%
        summarise_all(funs(mean))
mon6 <- forecast_error2 %>% select(variable, 'error_6month'=error) %>%
        mutate(error_6month = abs(error_6month)) %>% 
        group_by(variable) %>% 
          summarise_all(funs(mean))

final2 <- left_join(mon1, mon6) %>% 
          melt(id.vars = 'variable')
```

# Conclusion

```{r echo=FALSE}
names(final2) <- c('model', 'forecast_window' ,'error')
final2 %>% 
  ggplot(aes(x=model, y=error, fill=forecast_window)) +
 geom_bar(stat='identity', position='dodge') +
  labs(x='Month', y='Absolute error', title='forecasting error by forecast scenario') +
  theme(
    legend.position = 'top',
    legend.title=element_blank(),
    axis.text.x = element_text(angle=45, hjust=1) 
  )
```



We see that the models with seasonal and trend terms perform better than the simpler constant model in terms of forecasting accuracy. 

A surprising finding is that, with the exception of the constant model, the models performed better on medium-term forecasts compared to short term forecasts. 

I began this paper expecting to prove that constantly refitting time series models with the latest data would improve forecasting accuracy. These results show that this is not always the case. **We have now seen that a model fit to forecast 6 months out can outperform an equivalent model forecasting 1 month out recalibrated every month.** 

This finding has implications about which models are ideal to use in the fredcast competition. Furthermore, in the case of *unemployment* the data is rounded to the nearest 1 decimal place (4.3, 3.9 etc). Error is further increased when the forecasts are rounded.

In future iterations of this work I intend to test more time series models and varying forecast scenarios. I also will apply these techniques to the other time series in the fredcast competitions, all of which exhibit very different behavior from the unemployment rate.

```{r eval=FALSE, include=FALSE}


dygraph(ets_forecasts1[[2]], main='test') %>% 
  dyRangeSelector(height=20, dateWindow = c('2016-06-01', '2018-12-01')) %>% 
  dyOptions(drawPoints=T, pointSize=3) %>% 
  dyHighlight(highlightCircleSize = 5, 
              highlightSeriesBackgroundAlpha = 0.3)
```
